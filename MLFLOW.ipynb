{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart: Compare runs, choose a model, and deploy it to a REST API\n",
    "\n",
    "In this quickstart, you will:\n",
    "\n",
    "- Run a hyperparameter sweep on a training script\n",
    "\n",
    "- Compare the results of the runs in the MLflow UI\n",
    "\n",
    "- Choose the best run and register it as a model\n",
    "\n",
    "- Deploy the model to a REST API\n",
    "\n",
    "- Build a container image suitable for deployment to a cloud platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.21.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.21.3 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.21.3-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow) (2.0.36)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached databricks_sdk-0.49.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (8.5.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading opentelemetry_api-1.32.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.32.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: packaging<25 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (4.25.5)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from mlflow-skinny==2.21.3->mlflow) (4.12.2)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\meddieek\\appdata\\roaming\\python\\python311\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Collecting Werkzeug>=3.1 (from Flask<4->mlflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\meddieek\\appdata\\roaming\\python\\python311\\site-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\meddieek\\appdata\\roaming\\python\\python311\\site-packages (from click<9,>=7.0->mlflow-skinny==2.21.3->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.20.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meddieek\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\gen-ai\\lab-scenarios\\.conda\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached mlflow-2.21.3-py3-none-any.whl (28.2 MB)\n",
      "Using cached mlflow_skinny-2.21.3-py3-none-any.whl (6.1 MB)\n",
      "Using cached alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached databricks_sdk-0.49.0-py3-none-any.whl (683 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.32.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_sdk-1.32.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl (188 kB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: Werkzeug, waitress, sqlparse, pyasn1, Mako, itsdangerous, graphql-core, deprecated, blinker, uvicorn, starlette, rsa, pyasn1-modules, opentelemetry-api, graphql-relay, Flask, docker, alembic, opentelemetry-semantic-conventions, graphene, google-auth, fastapi, opentelemetry-sdk, databricks-sdk, mlflow-skinny, mlflow\n",
      "  Attempting uninstall: Werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.4\n",
      "    Uninstalling Werkzeug-3.0.4:\n",
      "      Successfully uninstalled Werkzeug-3.0.4\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.8.2\n",
      "    Uninstalling blinker-1.8.2:\n",
      "      Successfully uninstalled blinker-1.8.2\n",
      "Successfully installed Flask-3.1.0 Mako-1.3.10 Werkzeug-3.1.3 alembic-1.15.2 blinker-1.9.0 databricks-sdk-0.49.0 deprecated-1.2.18 docker-7.1.0 fastapi-0.115.12 google-auth-2.38.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 itsdangerous-2.2.0 mlflow-2.21.3 mlflow-skinny-2.21.3 opentelemetry-api-1.32.0 opentelemetry-sdk-1.32.0 opentelemetry-semantic-conventions-0.53b0 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9 sqlparse-0.5.3 starlette-0.46.1 uvicorn-0.34.0 waitress-3.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dc13b94a-dd1f-482d-a4f5-3c80f951ca61",
       "rows": [
        [
         "0",
         "7.0",
         "0.27",
         "0.36",
         "20.7",
         "0.045",
         "45.0",
         "170.0",
         "1.001",
         "3.0",
         "0.45",
         "8.8",
         "6"
        ],
        [
         "1",
         "6.3",
         "0.3",
         "0.34",
         "1.6",
         "0.049",
         "14.0",
         "132.0",
         "0.994",
         "3.3",
         "0.49",
         "9.5",
         "6"
        ],
        [
         "2",
         "8.1",
         "0.28",
         "0.4",
         "6.9",
         "0.05",
         "30.0",
         "97.0",
         "0.9951",
         "3.26",
         "0.44",
         "10.1",
         "6"
        ],
        [
         "3",
         "7.2",
         "0.23",
         "0.32",
         "8.5",
         "0.058",
         "47.0",
         "186.0",
         "0.9956",
         "3.19",
         "0.4",
         "9.9",
         "6"
        ],
        [
         "4",
         "7.2",
         "0.23",
         "0.32",
         "8.5",
         "0.058",
         "47.0",
         "186.0",
         "0.9956",
         "3.19",
         "0.4",
         "9.9",
         "6"
        ],
        [
         "5",
         "8.1",
         "0.28",
         "0.4",
         "6.9",
         "0.05",
         "30.0",
         "97.0",
         "0.9951",
         "3.26",
         "0.44",
         "10.1",
         "6"
        ],
        [
         "6",
         "6.2",
         "0.32",
         "0.16",
         "7.0",
         "0.045",
         "30.0",
         "136.0",
         "0.9949",
         "3.18",
         "0.47",
         "9.6",
         "6"
        ],
        [
         "7",
         "7.0",
         "0.27",
         "0.36",
         "20.7",
         "0.045",
         "45.0",
         "170.0",
         "1.001",
         "3.0",
         "0.45",
         "8.8",
         "6"
        ],
        [
         "8",
         "6.3",
         "0.3",
         "0.34",
         "1.6",
         "0.049",
         "14.0",
         "132.0",
         "0.994",
         "3.3",
         "0.49",
         "9.5",
         "6"
        ],
        [
         "9",
         "8.1",
         "0.22",
         "0.43",
         "1.5",
         "0.044",
         "28.0",
         "129.0",
         "0.9938",
         "3.22",
         "0.45",
         "11.0",
         "6"
        ],
        [
         "10",
         "8.1",
         "0.27",
         "0.41",
         "1.45",
         "0.033",
         "11.0",
         "63.0",
         "0.9908",
         "2.99",
         "0.56",
         "12.0",
         "5"
        ],
        [
         "11",
         "8.6",
         "0.23",
         "0.4",
         "4.2",
         "0.035",
         "17.0",
         "109.0",
         "0.9947",
         "3.14",
         "0.53",
         "9.7",
         "5"
        ],
        [
         "12",
         "7.9",
         "0.18",
         "0.37",
         "1.2",
         "0.04",
         "16.0",
         "75.0",
         "0.992",
         "3.18",
         "0.63",
         "10.8",
         "5"
        ],
        [
         "13",
         "6.6",
         "0.16",
         "0.4",
         "1.5",
         "0.044",
         "48.0",
         "143.0",
         "0.9912",
         "3.54",
         "0.52",
         "12.4",
         "7"
        ],
        [
         "14",
         "8.3",
         "0.42",
         "0.62",
         "19.25",
         "0.04",
         "41.0",
         "172.0",
         "1.0002",
         "2.98",
         "0.67",
         "9.7",
         "5"
        ],
        [
         "15",
         "6.6",
         "0.17",
         "0.38",
         "1.5",
         "0.032",
         "28.0",
         "112.0",
         "0.9914",
         "3.25",
         "0.55",
         "11.4",
         "7"
        ],
        [
         "16",
         "6.3",
         "0.48",
         "0.04",
         "1.1",
         "0.046",
         "30.0",
         "99.0",
         "0.9928",
         "3.24",
         "0.36",
         "9.6",
         "6"
        ],
        [
         "17",
         "6.2",
         "0.66",
         "0.48",
         "1.2",
         "0.029",
         "29.0",
         "75.0",
         "0.9892",
         "3.33",
         "0.39",
         "12.8",
         "8"
        ],
        [
         "18",
         "7.4",
         "0.34",
         "0.42",
         "1.1",
         "0.033",
         "17.0",
         "171.0",
         "0.9917",
         "3.12",
         "0.53",
         "11.3",
         "6"
        ],
        [
         "19",
         "6.5",
         "0.31",
         "0.14",
         "7.5",
         "0.044",
         "34.0",
         "133.0",
         "0.9955",
         "3.22",
         "0.5",
         "9.5",
         "5"
        ],
        [
         "20",
         "6.2",
         "0.66",
         "0.48",
         "1.2",
         "0.029",
         "29.0",
         "75.0",
         "0.9892",
         "3.33",
         "0.39",
         "12.8",
         "8"
        ],
        [
         "21",
         "6.4",
         "0.31",
         "0.38",
         "2.9",
         "0.038",
         "19.0",
         "102.0",
         "0.9912",
         "3.17",
         "0.35",
         "11.0",
         "7"
        ],
        [
         "22",
         "6.8",
         "0.26",
         "0.42",
         "1.7",
         "0.049",
         "41.0",
         "122.0",
         "0.993",
         "3.47",
         "0.48",
         "10.5",
         "8"
        ],
        [
         "23",
         "7.6",
         "0.67",
         "0.14",
         "1.5",
         "0.074",
         "25.0",
         "168.0",
         "0.9937",
         "3.05",
         "0.51",
         "9.3",
         "5"
        ],
        [
         "24",
         "6.6",
         "0.27",
         "0.41",
         "1.3",
         "0.052",
         "16.0",
         "142.0",
         "0.9951",
         "3.42",
         "0.47",
         "10.0",
         "6"
        ],
        [
         "25",
         "7.0",
         "0.25",
         "0.32",
         "9.0",
         "0.046",
         "56.0",
         "245.0",
         "0.9955",
         "3.25",
         "0.5",
         "10.4",
         "6"
        ],
        [
         "26",
         "6.9",
         "0.24",
         "0.35",
         "1.0",
         "0.052",
         "35.0",
         "146.0",
         "0.993",
         "3.45",
         "0.44",
         "10.0",
         "6"
        ],
        [
         "27",
         "7.0",
         "0.28",
         "0.39",
         "8.7",
         "0.051",
         "32.0",
         "141.0",
         "0.9961",
         "3.38",
         "0.53",
         "10.5",
         "6"
        ],
        [
         "28",
         "7.4",
         "0.27",
         "0.48",
         "1.1",
         "0.047",
         "17.0",
         "132.0",
         "0.9914",
         "3.19",
         "0.49",
         "11.6",
         "6"
        ],
        [
         "29",
         "7.2",
         "0.32",
         "0.36",
         "2.0",
         "0.033",
         "37.0",
         "114.0",
         "0.9906",
         "3.1",
         "0.71",
         "12.3",
         "7"
        ],
        [
         "30",
         "8.5",
         "0.24",
         "0.39",
         "10.4",
         "0.044",
         "20.0",
         "142.0",
         "0.9974",
         "3.2",
         "0.53",
         "10.0",
         "6"
        ],
        [
         "31",
         "8.3",
         "0.14",
         "0.34",
         "1.1",
         "0.042",
         "7.0",
         "47.0",
         "0.9934",
         "3.47",
         "0.4",
         "10.2",
         "6"
        ],
        [
         "32",
         "7.4",
         "0.25",
         "0.36",
         "2.05",
         "0.05",
         "31.0",
         "100.0",
         "0.992",
         "3.19",
         "0.44",
         "10.8",
         "6"
        ],
        [
         "33",
         "6.2",
         "0.12",
         "0.34",
         "1.5",
         "0.045",
         "43.0",
         "117.0",
         "0.9939",
         "3.42",
         "0.51",
         "9.0",
         "6"
        ],
        [
         "34",
         "5.8",
         "0.27",
         "0.2",
         "14.95",
         "0.044",
         "22.0",
         "179.0",
         "0.9962",
         "3.37",
         "0.37",
         "10.2",
         "5"
        ],
        [
         "35",
         "7.3",
         "0.28",
         "0.43",
         "1.7",
         "0.08",
         "21.0",
         "123.0",
         "0.9905",
         "3.19",
         "0.42",
         "12.8",
         "5"
        ],
        [
         "36",
         "6.5",
         "0.39",
         "0.23",
         "5.4",
         "0.051",
         "25.0",
         "149.0",
         "0.9934",
         "3.24",
         "0.35",
         "10.0",
         "5"
        ],
        [
         "37",
         "7.0",
         "0.33",
         "0.32",
         "1.2",
         "0.053",
         "38.0",
         "138.0",
         "0.9906",
         "3.13",
         "0.28",
         "11.2",
         "6"
        ],
        [
         "38",
         "7.3",
         "0.24",
         "0.39",
         "17.95",
         "0.057",
         "45.0",
         "149.0",
         "0.9999",
         "3.21",
         "0.36",
         "8.6",
         "5"
        ],
        [
         "39",
         "7.3",
         "0.24",
         "0.39",
         "17.95",
         "0.057",
         "45.0",
         "149.0",
         "0.9999",
         "3.21",
         "0.36",
         "8.6",
         "5"
        ],
        [
         "40",
         "6.7",
         "0.23",
         "0.39",
         "2.5",
         "0.172",
         "63.0",
         "158.0",
         "0.9937",
         "3.11",
         "0.36",
         "9.4",
         "6"
        ],
        [
         "41",
         "6.7",
         "0.24",
         "0.39",
         "2.9",
         "0.173",
         "63.0",
         "157.0",
         "0.9937",
         "3.1",
         "0.34",
         "9.4",
         "6"
        ],
        [
         "42",
         "7.0",
         "0.31",
         "0.26",
         "7.4",
         "0.069",
         "28.0",
         "160.0",
         "0.9954",
         "3.13",
         "0.46",
         "9.8",
         "6"
        ],
        [
         "43",
         "6.6",
         "0.24",
         "0.27",
         "1.4",
         "0.057",
         "33.0",
         "152.0",
         "0.9934",
         "3.22",
         "0.56",
         "9.5",
         "6"
        ],
        [
         "44",
         "6.7",
         "0.23",
         "0.26",
         "1.4",
         "0.06",
         "33.0",
         "154.0",
         "0.9934",
         "3.24",
         "0.56",
         "9.5",
         "6"
        ],
        [
         "45",
         "7.4",
         "0.18",
         "0.31",
         "1.4",
         "0.058",
         "38.0",
         "167.0",
         "0.9931",
         "3.16",
         "0.53",
         "10.0",
         "7"
        ],
        [
         "46",
         "6.2",
         "0.45",
         "0.26",
         "4.4",
         "0.063",
         "63.0",
         "206.0",
         "0.994",
         "3.27",
         "0.52",
         "9.8",
         "4"
        ],
        [
         "47",
         "6.2",
         "0.46",
         "0.25",
         "4.4",
         "0.066",
         "62.0",
         "207.0",
         "0.9939",
         "3.25",
         "0.52",
         "9.8",
         "5"
        ],
        [
         "48",
         "7.0",
         "0.31",
         "0.26",
         "7.4",
         "0.069",
         "28.0",
         "160.0",
         "0.9954",
         "3.13",
         "0.46",
         "9.8",
         "6"
        ],
        [
         "49",
         "6.9",
         "0.19",
         "0.35",
         "5.0",
         "0.067",
         "32.0",
         "150.0",
         "0.995",
         "3.36",
         "0.48",
         "9.8",
         "5"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 4898
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the dataset\n",
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8e32db95-9967-4acb-afad-ab209fec20df",
       "rows": [
        [
         "2835",
         "6.3",
         "0.25",
         "0.22",
         "3.3",
         "0.048",
         "41.0",
         "161.0",
         "0.99256",
         "3.16",
         "0.5",
         "10.5",
         "6"
        ],
        [
         "1157",
         "7.8",
         "0.3",
         "0.29",
         "16.85",
         "0.054",
         "23.0",
         "135.0",
         "0.9998",
         "3.16",
         "0.38",
         "9.0",
         "6"
        ],
        [
         "744",
         "7.4",
         "0.38",
         "0.27",
         "7.5",
         "0.041",
         "24.0",
         "160.0",
         "0.99535",
         "3.17",
         "0.43",
         "10.0",
         "5"
        ],
        [
         "1448",
         "7.4",
         "0.16",
         "0.49",
         "1.2",
         "0.055",
         "18.0",
         "150.0",
         "0.9917",
         "3.23",
         "0.47",
         "11.2",
         "6"
        ],
        [
         "3338",
         "7.2",
         "0.27",
         "0.28",
         "15.2",
         "0.046",
         "6.0",
         "41.0",
         "0.99665",
         "3.17",
         "0.39",
         "10.9",
         "6"
        ],
        [
         "1965",
         "6.8",
         "0.27",
         "0.28",
         "13.3",
         "0.076",
         "50.0",
         "163.0",
         "0.9979",
         "3.03",
         "0.38",
         "8.6",
         "6"
        ],
        [
         "3026",
         "8.4",
         "0.22",
         "0.3",
         "8.9",
         "0.024",
         "17.0",
         "118.0",
         "0.99456",
         "2.99",
         "0.34",
         "10.5",
         "6"
        ],
        [
         "783",
         "8.1",
         "0.17",
         "0.44",
         "14.1",
         "0.053",
         "43.0",
         "145.0",
         "1.0006",
         "3.28",
         "0.75",
         "8.8",
         "8"
        ],
        [
         "4192",
         "6.7",
         "0.2",
         "0.24",
         "6.5",
         "0.044",
         "28.0",
         "100.0",
         "0.99348",
         "3.12",
         "0.33",
         "10.2",
         "6"
        ],
        [
         "3607",
         "6.8",
         "0.14",
         "0.18",
         "1.4",
         "0.047",
         "30.0",
         "90.0",
         "0.99164",
         "3.27",
         "0.54",
         "11.2",
         "6"
        ],
        [
         "229",
         "7.1",
         "0.24",
         "0.41",
         "17.8",
         "0.046",
         "39.0",
         "145.0",
         "0.9998",
         "3.32",
         "0.39",
         "8.7",
         "5"
        ],
        [
         "857",
         "8.2",
         "0.4",
         "0.48",
         "13.7",
         "0.042",
         "59.0",
         "169.0",
         "0.9986",
         "3.1",
         "0.52",
         "9.4",
         "5"
        ],
        [
         "2178",
         "7.6",
         "0.32",
         "0.58",
         "16.75",
         "0.05",
         "43.0",
         "163.0",
         "0.9999",
         "3.15",
         "0.54",
         "9.2",
         "5"
        ],
        [
         "2280",
         "6.4",
         "0.16",
         "0.25",
         "1.3",
         "0.047",
         "20.0",
         "77.0",
         "0.9933",
         "3.61",
         "0.54",
         "10.2",
         "6"
        ],
        [
         "408",
         "6.3",
         "0.14",
         "0.39",
         "1.2",
         "0.044",
         "26.0",
         "116.0",
         "0.992",
         "3.26",
         "0.53",
         "10.3",
         "6"
        ],
        [
         "170",
         "7.1",
         "0.3",
         "0.46",
         "1.5",
         "0.066",
         "29.0",
         "133.0",
         "0.9906",
         "3.12",
         "0.54",
         "12.7",
         "6"
        ],
        [
         "540",
         "6.7",
         "0.31",
         "0.31",
         "9.9",
         "0.04",
         "10.0",
         "175.0",
         "0.9953",
         "3.46",
         "0.55",
         "11.4",
         "4"
        ],
        [
         "2460",
         "6.6",
         "0.33",
         "0.24",
         "16.05",
         "0.045",
         "31.0",
         "147.0",
         "0.99822",
         "3.08",
         "0.52",
         "9.2",
         "5"
        ],
        [
         "3917",
         "6.2",
         "0.28",
         "0.51",
         "7.9",
         "0.056",
         "49.0",
         "206.0",
         "0.9956",
         "3.18",
         "0.52",
         "9.4",
         "5"
        ],
        [
         "3221",
         "6.6",
         "0.24",
         "0.38",
         "12.75",
         "0.034",
         "8.0",
         "74.0",
         "0.99386",
         "3.1",
         "0.57",
         "12.9",
         "6"
        ],
        [
         "1957",
         "7.0",
         "0.12",
         "0.32",
         "7.2",
         "0.058",
         "22.0",
         "89.0",
         "0.9966",
         "3.29",
         "0.38",
         "9.2",
         "6"
        ],
        [
         "2915",
         "6.9",
         "0.14",
         "0.38",
         "1.0",
         "0.041",
         "22.0",
         "81.0",
         "0.99043",
         "3.03",
         "0.54",
         "11.4",
         "6"
        ],
        [
         "1691",
         "7.2",
         "0.25",
         "0.28",
         "14.4",
         "0.055",
         "55.0",
         "205.0",
         "0.9986",
         "3.12",
         "0.38",
         "9.0",
         "7"
        ],
        [
         "3317",
         "5.6",
         "0.32",
         "0.32",
         "8.3",
         "0.043",
         "32.0",
         "105.0",
         "0.99266",
         "3.24",
         "0.47",
         "11.2",
         "6"
        ],
        [
         "1161",
         "7.8",
         "0.3",
         "0.29",
         "16.85",
         "0.054",
         "23.0",
         "135.0",
         "0.9998",
         "3.16",
         "0.38",
         "9.0",
         "6"
        ],
        [
         "4050",
         "7.4",
         "0.16",
         "0.27",
         "15.5",
         "0.05",
         "25.0",
         "135.0",
         "0.9984",
         "2.9",
         "0.43",
         "8.7",
         "7"
        ],
        [
         "2379",
         "6.4",
         "0.27",
         "0.19",
         "2.0",
         "0.084",
         "21.0",
         "191.0",
         "0.99516",
         "3.49",
         "0.63",
         "9.6",
         "4"
        ],
        [
         "4200",
         "8.0",
         "0.24",
         "0.33",
         "1.2",
         "0.044",
         "28.0",
         "101.0",
         "0.99035",
         "3.03",
         "0.43",
         "12.5",
         "6"
        ],
        [
         "2341",
         "7.2",
         "0.34",
         "0.3",
         "8.4",
         "0.051",
         "40.0",
         "167.0",
         "0.99756",
         "3.48",
         "0.62",
         "9.7",
         "5"
        ],
        [
         "1360",
         "6.2",
         "0.12",
         "0.26",
         "5.7",
         "0.044",
         "56.0",
         "158.0",
         "0.9951",
         "3.52",
         "0.37",
         "10.5",
         "6"
        ],
        [
         "3940",
         "6.9",
         "0.4",
         "0.37",
         "8.9",
         "0.053",
         "36.0",
         "148.0",
         "0.996",
         "3.16",
         "0.5",
         "9.3",
         "5"
        ],
        [
         "564",
         "6.8",
         "0.51",
         "0.3",
         "4.2",
         "0.066",
         "38.0",
         "165.0",
         "0.9945",
         "3.2",
         "0.42",
         "9.1",
         "5"
        ],
        [
         "3983",
         "5.6",
         "0.23",
         "0.25",
         "8.0",
         "0.043",
         "31.0",
         "101.0",
         "0.99429",
         "3.19",
         "0.42",
         "10.4",
         "6"
        ],
        [
         "4166",
         "5.8",
         "0.23",
         "0.31",
         "3.5",
         "0.044",
         "35.0",
         "158.0",
         "0.98998",
         "3.19",
         "0.37",
         "12.1",
         "7"
        ],
        [
         "2133",
         "8.3",
         "0.24",
         "0.27",
         "2.1",
         "0.03",
         "22.0",
         "162.0",
         "0.9914",
         "2.99",
         "0.68",
         "11.9",
         "6"
        ],
        [
         "1292",
         "6.2",
         "0.17",
         "0.3",
         "1.1",
         "0.037",
         "14.0",
         "79.0",
         "0.993",
         "3.5",
         "0.54",
         "10.3",
         "6"
        ],
        [
         "1595",
         "6.4",
         "0.27",
         "0.49",
         "7.3",
         "0.046",
         "53.0",
         "206.0",
         "0.9956",
         "3.24",
         "0.43",
         "9.2",
         "6"
        ],
        [
         "4024",
         "6.0",
         "0.28",
         "0.27",
         "4.1",
         "0.046",
         "50.0",
         "147.0",
         "0.99126",
         "3.27",
         "0.56",
         "11.6",
         "6"
        ],
        [
         "3308",
         "6.4",
         "0.35",
         "0.28",
         "12.6",
         "0.039",
         "19.0",
         "124.0",
         "0.99539",
         "3.2",
         "0.43",
         "10.6",
         "6"
        ],
        [
         "2543",
         "6.5",
         "0.23",
         "0.25",
         "17.3",
         "0.046",
         "15.0",
         "110.0",
         "0.99828",
         "3.15",
         "0.42",
         "9.2",
         "6"
        ],
        [
         "2399",
         "6.1",
         "0.16",
         "0.24",
         "1.4",
         "0.046",
         "17.0",
         "77.0",
         "0.99319",
         "3.66",
         "0.57",
         "10.3",
         "6"
        ],
        [
         "3226",
         "5.7",
         "0.2",
         "0.3",
         "2.5",
         "0.046",
         "38.0",
         "125.0",
         "0.99276",
         "3.34",
         "0.5",
         "9.9",
         "6"
        ],
        [
         "1172",
         "7.6",
         "0.21",
         "0.44",
         "1.9",
         "0.036",
         "10.0",
         "119.0",
         "0.9913",
         "3.01",
         "0.7",
         "12.8",
         "6"
        ],
        [
         "4828",
         "6.4",
         "0.23",
         "0.35",
         "10.3",
         "0.042",
         "54.0",
         "140.0",
         "0.9967",
         "3.23",
         "0.47",
         "9.2",
         "5"
        ],
        [
         "325",
         "7.5",
         "0.27",
         "0.31",
         "5.8",
         "0.057",
         "131.0",
         "313.0",
         "0.9946",
         "3.18",
         "0.59",
         "10.5",
         "5"
        ],
        [
         "1051",
         "6.9",
         "0.21",
         "0.81",
         "1.1",
         "0.137",
         "52.0",
         "123.0",
         "0.9932",
         "3.03",
         "0.39",
         "9.2",
         "6"
        ],
        [
         "2843",
         "5.9",
         "0.22",
         "0.38",
         "1.3",
         "0.046",
         "24.0",
         "90.0",
         "0.99232",
         "3.2",
         "0.47",
         "10.0",
         "6"
        ],
        [
         "3181",
         "8.3",
         "0.16",
         "0.37",
         "7.9",
         "0.025",
         "38.0",
         "107.0",
         "0.99306",
         "2.93",
         "0.37",
         "11.9",
         "6"
        ],
        [
         "1351",
         "6.5",
         "0.37",
         "0.33",
         "3.9",
         "0.027",
         "40.0",
         "130.0",
         "0.9906",
         "3.28",
         "0.39",
         "12.7",
         "7"
        ],
        [
         "3460",
         "6.8",
         "0.19",
         "0.4",
         "9.85",
         "0.055",
         "41.0",
         "103.0",
         "0.99532",
         "2.98",
         "0.56",
         "10.5",
         "6"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3673
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>41.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.054</td>\n",
       "      <td>23.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.041</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.99535</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.055</td>\n",
       "      <td>18.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "2835            6.3              0.25         0.22            3.30      0.048   \n",
       "1157            7.8              0.30         0.29           16.85      0.054   \n",
       "744             7.4              0.38         0.27            7.50      0.041   \n",
       "1448            7.4              0.16         0.49            1.20      0.055   \n",
       "3338            7.2              0.27         0.28           15.20      0.046   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "2835                 41.0                 161.0  0.99256  3.16       0.50   \n",
       "1157                 23.0                 135.0  0.99980  3.16       0.38   \n",
       "744                  24.0                 160.0  0.99535  3.17       0.43   \n",
       "1448                 18.0                 150.0  0.99170  3.23       0.47   \n",
       "3338                  6.0                  41.0  0.99665  3.17       0.39   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "2835     10.5        6  \n",
       "1157      9.0        6  \n",
       "744      10.0        5  \n",
       "1448     11.2        6  \n",
       "3338     10.9        6  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split the data into training,validation and test sets\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.25,random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 5, ..., 6, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train.drop(['quality'],axis=1).values\n",
    "train_y=train[['quality']].values.ravel()\n",
    "\n",
    "## test dataset\n",
    "test_x=test.drop(['quality'],axis=1).values\n",
    "test_y=test[['quality']].values.ravel()\n",
    "\n",
    "## splitting this train data into train and validation\n",
    "\n",
    "train_x,valid_x,train_y,valid_y=train_test_split(train_x,train_y,test_size=0.20,random_state=42)\n",
    "\n",
    "signature=infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.86621852e+00, 2.80377808e-01, 3.32597005e-01, 6.42164738e+00,\n",
       "       4.55513955e-02, 3.53556841e+01, 1.38792376e+02, 9.94074221e-01,\n",
       "       3.18919333e+00, 4.88396869e-01, 1.05005673e+01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## Define model architecture\n",
    "    mean=np.mean(train_x,axis=0)\n",
    "    var=np.var(train_x,axis=0)\n",
    "\n",
    "    model=keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params wwith MLFLOW tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=64)\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "\n",
    "        eval_rmse=eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "\n",
    "        ## log the model\n",
    "\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 20:28:20 INFO mlflow.tracking.fluent: Experiment with name 'wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 1s/step - loss: 33.6452 - root_mean_squared_error: 5.8068\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.7195 - root_mean_squared_error: 5.8068\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 33.8562 - root_mean_squared_error: 5.8068\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.5634 - root_mean_squared_error: 5.7933\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.3334 - root_mean_squared_error: 5.7733\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33.1189 - root_mean_squared_error: 5.7546 \n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.8325 - root_mean_squared_error: 5.7296 \n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.6948 - root_mean_squared_error: 5.7175 \n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.5453 - root_mean_squared_error: 5.7043 \n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.3988 - root_mean_squared_error: 5.6913\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1108 - root_mean_squared_error: 5.6519\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2527 - root_mean_squared_error: 5.6658\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.9553 - root_mean_squared_error: 5.6519\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7974 - root_mean_squared_error: 5.6377\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.6380 - root_mean_squared_error: 5.6233 \n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.4764 - root_mean_squared_error: 5.6087\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.3192 - root_mean_squared_error: 5.5945\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.1582 - root_mean_squared_error: 5.5798\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.9953 - root_mean_squared_error: 5.5649\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.8343 - root_mean_squared_error: 5.5502\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.6732 - root_mean_squared_error: 5.5354\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.5139 - root_mean_squared_error: 5.5207\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.3555 - root_mean_squared_error: 5.5060\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 30.1976 - root_mean_squared_error: 5.4913\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 30.0391 - root_mean_squared_error: 5.4765\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.8825 - root_mean_squared_error: 5.4618\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.7251 - root_mean_squared_error: 5.4470\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.5703 - root_mean_squared_error: 5.4324\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 29.4165 - root_mean_squared_error: 5.4179\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 29.2646 - root_mean_squared_error: 5.4034\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 29.1149 - root_mean_squared_error: 5.3892\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 28.9660 - root_mean_squared_error: 5.3749\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28.8172 - root_mean_squared_error: 5.3607\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.6691 - root_mean_squared_error: 5.3464\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.5215 - root_mean_squared_error: 5.3321\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.3751 - root_mean_squared_error: 5.3179\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.2297 - root_mean_squared_error: 5.3038\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 28.0855 - root_mean_squared_error: 5.2897\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27.9423 - root_mean_squared_error: 5.2757\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.7999 - root_mean_squared_error: 5.2617\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.5190 - root_mean_squared_error: 5.2339\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.6586 - root_mean_squared_error: 5.2477\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.3802 - root_mean_squared_error: 5.2201\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.2425 - root_mean_squared_error: 5.2064\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.1066 - root_mean_squared_error: 5.1928\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 26.9765 - root_mean_squared_error: 5.1798 - val_loss: 10.8551 - val_root_mean_squared_error: 3.2947\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 11.0897 - root_mean_squared_error: 3.2235\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4024 - root_mean_squared_error: 3.2235\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.1355 - root_mean_squared_error: 3.1741\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.2459 - root_mean_squared_error: 3.1741\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.1109 - root_mean_squared_error: 3.1741\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.0803 - root_mean_squared_error: 3.1548\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9940 - root_mean_squared_error: 3.1429\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.0324 - root_mean_squared_error: 3.1429\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9571 - root_mean_squared_error: 3.1429\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.9239 - root_mean_squared_error: 3.1429\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8821 - root_mean_squared_error: 3.1429\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8352 - root_mean_squared_error: 3.1354\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7879 - root_mean_squared_error: 3.1278  \n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7383 - root_mean_squared_error: 3.1198 \n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6889 - root_mean_squared_error: 3.1118 \n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6387 - root_mean_squared_error: 3.1036 \n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5882 - root_mean_squared_error: 3.0953 \n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.5369 - root_mean_squared_error: 3.0869\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.4859 - root_mean_squared_error: 3.0785\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.4328 - root_mean_squared_error: 3.0697\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.3810 - root_mean_squared_error: 3.0611\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.3283 - root_mean_squared_error: 3.0523\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.2779 - root_mean_squared_error: 3.0438\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.2278 - root_mean_squared_error: 3.0354\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.1790 - root_mean_squared_error: 3.0272\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.1288 - root_mean_squared_error: 3.0187\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.0796 - root_mean_squared_error: 3.0103\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.0324 - root_mean_squared_error: 3.0023\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.9888 - root_mean_squared_error: 2.9949\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.9455 - root_mean_squared_error: 2.9875\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.9026 - root_mean_squared_error: 2.9801\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.8620 - root_mean_squared_error: 2.9732\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.8208 - root_mean_squared_error: 2.9661\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.7806 - root_mean_squared_error: 2.9591\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.7410 - root_mean_squared_error: 2.9523\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.7019 - root_mean_squared_error: 2.9455\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.6625 - root_mean_squared_error: 2.9386\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.6230 - root_mean_squared_error: 2.9317\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5832 - root_mean_squared_error: 2.9247\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5438 - root_mean_squared_error: 2.9178\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5049 - root_mean_squared_error: 2.9109\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.4669 - root_mean_squared_error: 2.9042\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.4297 - root_mean_squared_error: 2.8976\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3925 - root_mean_squared_error: 2.8910\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3563 - root_mean_squared_error: 2.8845\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3204 - root_mean_squared_error: 2.8781\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.2860 - root_mean_squared_error: 2.8720 - val_loss: 4.0396 - val_root_mean_squared_error: 2.0099\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2087 - root_mean_squared_error: 2.0063\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0406 - root_mean_squared_error: 1.9777\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 4.8279 - root_mean_squared_error: 2.0063\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9269 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7948 - root_mean_squared_error: 1.9444\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8338 - root_mean_squared_error: 1.9319\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4859 - root_mean_squared_error: 1.9319\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7437 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7497 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7496 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7677 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7479 - root_mean_squared_error: 1.9337\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7446 - root_mean_squared_error: 1.9330\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7383 - root_mean_squared_error: 1.9315\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7322 - root_mean_squared_error: 1.9301 \n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.7269 - root_mean_squared_error: 1.9288\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.7239 - root_mean_squared_error: 1.9281\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.7210 - root_mean_squared_error: 1.9275\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7169 - root_mean_squared_error: 1.9265\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7134 - root_mean_squared_error: 1.9256\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7087 - root_mean_squared_error: 1.9245\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7053 - root_mean_squared_error: 1.9236\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7001 - root_mean_squared_error: 1.9223\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6951 - root_mean_squared_error: 1.9211\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6883 - root_mean_squared_error: 1.9193\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6807 - root_mean_squared_error: 1.9174\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6724 - root_mean_squared_error: 1.9152\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6634 - root_mean_squared_error: 1.9129\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6540 - root_mean_squared_error: 1.9104\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6441 - root_mean_squared_error: 1.9078\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6356 - root_mean_squared_error: 1.9056\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6267 - root_mean_squared_error: 1.9032\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6176 - root_mean_squared_error: 1.9008\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6084 - root_mean_squared_error: 1.8984\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5989 - root_mean_squared_error: 1.8958\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5899 - root_mean_squared_error: 1.8935\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5805 - root_mean_squared_error: 1.8910\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5710 - root_mean_squared_error: 1.8884\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5612 - root_mean_squared_error: 1.8858\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5517 - root_mean_squared_error: 1.8832\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5423 - root_mean_squared_error: 1.8807\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5330 - root_mean_squared_error: 1.8782\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5244 - root_mean_squared_error: 1.8758\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5156 - root_mean_squared_error: 1.8735\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5069 - root_mean_squared_error: 1.8711\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4981 - root_mean_squared_error: 1.8687\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4896 - root_mean_squared_error: 1.8664 - val_loss: 2.6554 - val_root_mean_squared_error: 1.6295\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 2.2713 - root_mean_squared_error: 1.5071\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2814 - root_mean_squared_error: 1.5104\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4072 - root_mean_squared_error: 1.5505\n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4719 - root_mean_squared_error: 1.5711\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4928 - root_mean_squared_error: 1.5779\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5125 - root_mean_squared_error: 1.5876\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5230 - root_mean_squared_error: 1.5947 \n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5456 - root_mean_squared_error: 1.5947 \n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5622 - root_mean_squared_error: 1.5999 \n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5737 - root_mean_squared_error: 1.6036 \n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5807 - root_mean_squared_error: 1.6058 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5869 - root_mean_squared_error: 1.6078 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5922 - root_mean_squared_error: 1.6094\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 2s/step - loss: 37.7136 - root_mean_squared_error: 6.1411\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37.3529 - root_mean_squared_error: 6.1116\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37.2700 - root_mean_squared_error: 6.1049\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.2747 - root_mean_squared_error: 6.1061\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.2848 - root_mean_squared_error: 6.1061\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.2625 - root_mean_squared_error: 6.1043 \n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.2306 - root_mean_squared_error: 6.1017 \n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.2183 - root_mean_squared_error: 6.1007 \n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.1825 - root_mean_squared_error: 6.0977\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.1319 - root_mean_squared_error: 6.0936\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.0899 - root_mean_squared_error: 6.0901\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.0493 - root_mean_squared_error: 6.0868\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 37.0129 - root_mean_squared_error: 6.0838\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 36.9732 - root_mean_squared_error: 6.0805\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 36.9359 - root_mean_squared_error: 6.0744\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 36.8992 - root_mean_squared_error: 6.0744\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 36.8657 - root_mean_squared_error: 6.0716\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 36.8327 - root_mean_squared_error: 6.0689\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 36.7973 - root_mean_squared_error: 6.0660\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 36.7613 - root_mean_squared_error: 6.0630\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 36.7262 - root_mean_squared_error: 6.0601\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 36.6867 - root_mean_squared_error: 6.0568\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 36.6457 - root_mean_squared_error: 6.0534\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 36.6008 - root_mean_squared_error: 6.0497\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.5535 - root_mean_squared_error: 6.0457\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 36.5051 - root_mean_squared_error: 6.0417\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 36.4594 - root_mean_squared_error: 6.0379\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.4136 - root_mean_squared_error: 6.0341\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.3677 - root_mean_squared_error: 6.0302\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.3192 - root_mean_squared_error: 6.0262\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.2712 - root_mean_squared_error: 6.0222\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.2241 - root_mean_squared_error: 6.0182\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 36.1759 - root_mean_squared_error: 6.0142\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 36.1279 - root_mean_squared_error: 6.0102\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 36.0805 - root_mean_squared_error: 6.0062\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 36.0339 - root_mean_squared_error: 6.0023\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 35.9867 - root_mean_squared_error: 5.9983\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 35.9383 - root_mean_squared_error: 5.9942\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 35.8909 - root_mean_squared_error: 5.9902\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 35.8451 - root_mean_squared_error: 5.9864\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 35.7996 - root_mean_squared_error: 5.9825\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 35.7538 - root_mean_squared_error: 5.9787\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 35.7085 - root_mean_squared_error: 5.9748\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 35.6633 - root_mean_squared_error: 5.9710\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 35.6201 - root_mean_squared_error: 5.9674 - val_loss: 29.9422 - val_root_mean_squared_error: 5.4719\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.2809 - root_mean_squared_error: 5.4184\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.3597 - root_mean_squared_error: 5.4184\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - loss: 29.3923 - root_mean_squared_error: 5.4112\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.3962 - root_mean_squared_error: 5.4218\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3883 - root_mean_squared_error: 5.4204\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.3917 - root_mean_squared_error: 5.4211\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3098 - root_mean_squared_error: 5.4138\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 29.3812 - root_mean_squared_error: 5.4138\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.2091 - root_mean_squared_error: 5.4045\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.0603 - root_mean_squared_error: 5.3907\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.2532 - root_mean_squared_error: 5.4045\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.1043 - root_mean_squared_error: 5.3872\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.0227 - root_mean_squared_error: 5.3872\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.0113 - root_mean_squared_error: 5.3861\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 29.0042 - root_mean_squared_error: 5.3855\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28.9972 - root_mean_squared_error: 5.3848\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.9869 - root_mean_squared_error: 5.3839\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 28.9701 - root_mean_squared_error: 5.3823\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 28.9458 - root_mean_squared_error: 5.3800\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 28.9192 - root_mean_squared_error: 5.3776\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 28.8879 - root_mean_squared_error: 5.3714\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 28.8530 - root_mean_squared_error: 5.3714\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 28.8220 - root_mean_squared_error: 5.3685\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 28.7946 - root_mean_squared_error: 5.3659\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 28.7670 - root_mean_squared_error: 5.3633\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 28.7391 - root_mean_squared_error: 5.3607\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 28.7101 - root_mean_squared_error: 5.3580\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.6829 - root_mean_squared_error: 5.3554\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.6537 - root_mean_squared_error: 5.3527\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.6217 - root_mean_squared_error: 5.3497\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.5901 - root_mean_squared_error: 5.3467\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.5582 - root_mean_squared_error: 5.3437\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.5280 - root_mean_squared_error: 5.3409\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.4950 - root_mean_squared_error: 5.3378\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.4604 - root_mean_squared_error: 5.3345\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.4255 - root_mean_squared_error: 5.3312\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.3916 - root_mean_squared_error: 5.3280\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.3589 - root_mean_squared_error: 5.3249\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.3265 - root_mean_squared_error: 5.3218\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.2944 - root_mean_squared_error: 5.3188\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.2625 - root_mean_squared_error: 5.3157\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.2320 - root_mean_squared_error: 5.3129\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.2023 - root_mean_squared_error: 5.3100\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 28.1730 - root_mean_squared_error: 5.3073\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 28.1434 - root_mean_squared_error: 5.3044\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 28.1138 - root_mean_squared_error: 5.3016\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 28.0855 - root_mean_squared_error: 5.2989 - val_loss: 23.7660 - val_root_mean_squared_error: 4.8750\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.5591 - root_mean_squared_error: 4.7494\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 766ms/step - loss: 22.1249 - root_mean_squared_error: 4.7494\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.3655 - root_mean_squared_error: 4.8505\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.5346 - root_mean_squared_error: 4.8505\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.0803 - root_mean_squared_error: 4.8505\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.6986 - root_mean_squared_error: 4.8676\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.6317 - root_mean_squared_error: 4.8654\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.6786 - root_mean_squared_error: 4.8676\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.7090 - root_mean_squared_error: 4.8659\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.6441 - root_mean_squared_error: 4.8621\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.5924 - root_mean_squared_error: 4.8568  \n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 23.6811 - root_mean_squared_error: 4.8568   \n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.5476 - root_mean_squared_error: 4.8522  \n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.5005 - root_mean_squared_error: 4.8473\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.4588 - root_mean_squared_error: 4.8430\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23.4312 - root_mean_squared_error: 4.8402\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23.4022 - root_mean_squared_error: 4.8372\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23.3715 - root_mean_squared_error: 4.8340\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23.3444 - root_mean_squared_error: 4.8312\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23.3144 - root_mean_squared_error: 4.8281\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23.2846 - root_mean_squared_error: 4.8250\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 23.2522 - root_mean_squared_error: 4.8217\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 23.2240 - root_mean_squared_error: 4.8187\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 23.1990 - root_mean_squared_error: 4.8161\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.1703 - root_mean_squared_error: 4.8131\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 23.1118 - root_mean_squared_error: 4.8071\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.0813 - root_mean_squared_error: 4.8039\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.1418 - root_mean_squared_error: 4.8102\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.0526 - root_mean_squared_error: 4.8009\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 23.0233 - root_mean_squared_error: 4.7978\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.9939 - root_mean_squared_error: 4.7947\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.9640 - root_mean_squared_error: 4.7916\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22.9344 - root_mean_squared_error: 4.7885\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 22.9046 - root_mean_squared_error: 4.7853\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 22.8762 - root_mean_squared_error: 4.7824\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 22.8468 - root_mean_squared_error: 4.7793\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22.8181 - root_mean_squared_error: 4.7762\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22.7882 - root_mean_squared_error: 4.7731\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 22.7572 - root_mean_squared_error: 4.7698\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.7254 - root_mean_squared_error: 4.7665\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.6942 - root_mean_squared_error: 4.7631\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.6633 - root_mean_squared_error: 4.7599\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.6324 - root_mean_squared_error: 4.7566\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22.6027 - root_mean_squared_error: 4.7534\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 22.5731 - root_mean_squared_error: 4.7503\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 22.5437 - root_mean_squared_error: 4.7472\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 22.5156 - root_mean_squared_error: 4.7442 - val_loss: 18.8257 - val_root_mean_squared_error: 4.3389\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 271ms/step - loss: 18.9041 - root_mean_squared_error: 4.3479\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 18.8935 - root_mean_squared_error: 4.3467\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 18.7955 - root_mean_squared_error: 4.3354 \n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 18.7503 - root_mean_squared_error: 4.3285 \n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.7360 - root_mean_squared_error: 4.3285 \n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18.7141 - root_mean_squared_error: 4.3260 \n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18.6787 - root_mean_squared_error: 4.3219 \n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 18.6542 - root_mean_squared_error: 4.3164\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 18.6316 - root_mean_squared_error: 4.3164\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 18.6325 - root_mean_squared_error: 4.3165\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 18.6306 - root_mean_squared_error: 4.3165\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 18.6486 - root_mean_squared_error: 4.3184\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 18.6622 - root_mean_squared_error: 4.3199\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 1s/step - loss: 45.0517 - root_mean_squared_error: 6.7121\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 44.0280 - root_mean_squared_error: 6.6349\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.9058 - root_mean_squared_error: 6.5488\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.7958 - root_mean_squared_error: 6.4621\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 40.6276 - root_mean_squared_error: 6.3689\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.1413 - root_mean_squared_error: 5.9966\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.7303 - root_mean_squared_error: 5.8739\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.4199 - root_mean_squared_error: 5.9342\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.0762 - root_mean_squared_error: 5.7600\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.4508 - root_mean_squared_error: 5.7600\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.8477 - root_mean_squared_error: 5.7053\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.2606 - root_mean_squared_error: 5.6514\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.6904 - root_mean_squared_error: 5.5469\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 31.1415 - root_mean_squared_error: 5.5469\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.6116 - root_mean_squared_error: 5.4965\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1010 - root_mean_squared_error: 5.4475\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 29.6057 - root_mean_squared_error: 5.3995\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29.1269 - root_mean_squared_error: 5.3526\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 28.6632 - root_mean_squared_error: 5.3066\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 28.2148 - root_mean_squared_error: 5.2618\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 27.7808 - root_mean_squared_error: 5.2180\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27.3595 - root_mean_squared_error: 5.1751\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 26.9525 - root_mean_squared_error: 5.1333\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 26.5604 - root_mean_squared_error: 5.0927\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 26.1800 - root_mean_squared_error: 5.0530\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25.8120 - root_mean_squared_error: 5.0143\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25.4547 - root_mean_squared_error: 4.9763\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 25.1089 - root_mean_squared_error: 4.9394\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.7747 - root_mean_squared_error: 4.9034\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.4525 - root_mean_squared_error: 4.8685\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.1400 - root_mean_squared_error: 4.8345\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 23.8366 - root_mean_squared_error: 4.8011\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 23.5426 - root_mean_squared_error: 4.7687\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23.2568 - root_mean_squared_error: 4.7369\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 22.9788 - root_mean_squared_error: 4.7058\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 22.7084 - root_mean_squared_error: 4.6753\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 22.4457 - root_mean_squared_error: 4.6456\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22.1897 - root_mean_squared_error: 4.6164\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 21.9406 - root_mean_squared_error: 4.5878\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 21.6980 - root_mean_squared_error: 4.5598\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 21.4617 - root_mean_squared_error: 4.5324\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 21.2321 - root_mean_squared_error: 4.5057\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 21.0122 - root_mean_squared_error: 4.4800 - val_loss: 2.3946 - val_root_mean_squared_error: 1.5474\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 1.4768 - root_mean_squared_error: 1.2781\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7519 - root_mean_squared_error: 1.3212\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7875 - root_mean_squared_error: 1.3350\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6375 - root_mean_squared_error: 1.3212\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8443 - root_mean_squared_error: 1.3619\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8587 - root_mean_squared_error: 1.3622\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8254 - root_mean_squared_error: 1.3622\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8591 - root_mean_squared_error: 1.3641\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8639 - root_mean_squared_error: 1.3656\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8678 - root_mean_squared_error: 1.3656\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8862 - root_mean_squared_error: 1.3724\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8756 - root_mean_squared_error: 1.3724\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8958 - root_mean_squared_error: 1.3760\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9023 - root_mean_squared_error: 1.3783\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9088 - root_mean_squared_error: 1.3807\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.9186 - root_mean_squared_error: 1.3843\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9273 - root_mean_squared_error: 1.3874\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9322 - root_mean_squared_error: 1.3892\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9355 - root_mean_squared_error: 1.3904\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9381 - root_mean_squared_error: 1.3914\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9406 - root_mean_squared_error: 1.3924\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9401 - root_mean_squared_error: 1.3924\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9404 - root_mean_squared_error: 1.3923\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9393 - root_mean_squared_error: 1.3919\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9380 - root_mean_squared_error: 1.3915\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9362 - root_mean_squared_error: 1.3909\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9332 - root_mean_squared_error: 1.3898\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9298 - root_mean_squared_error: 1.3886\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9262 - root_mean_squared_error: 1.3873\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9231 - root_mean_squared_error: 1.3862\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9204 - root_mean_squared_error: 1.3852\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9179 - root_mean_squared_error: 1.3843\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9150 - root_mean_squared_error: 1.3833\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9120 - root_mean_squared_error: 1.3822\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9088 - root_mean_squared_error: 1.3810\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9059 - root_mean_squared_error: 1.3800\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9031 - root_mean_squared_error: 1.3790\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9000 - root_mean_squared_error: 1.3778\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8972 - root_mean_squared_error: 1.3768\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8946 - root_mean_squared_error: 1.3759\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8920 - root_mean_squared_error: 1.3749\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8895 - root_mean_squared_error: 1.3740\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8872 - root_mean_squared_error: 1.3732\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8849 - root_mean_squared_error: 1.3724\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8825 - root_mean_squared_error: 1.3715\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8804 - root_mean_squared_error: 1.3707\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.8783 - root_mean_squared_error: 1.3700 - val_loss: 1.6360 - val_root_mean_squared_error: 1.2791\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - loss: 1.3010 - root_mean_squared_error: 1.1297\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2764 - root_mean_squared_error: 1.1297\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3380 - root_mean_squared_error: 1.1730\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3856 - root_mean_squared_error: 1.1957\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3620 - root_mean_squared_error: 1.1957\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3771 - root_mean_squared_error: 1.1846\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4446 - root_mean_squared_error: 1.2030\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4048 - root_mean_squared_error: 1.1957\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4485 - root_mean_squared_error: 1.2030\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2984 - root_mean_squared_error: 1.1957\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4310 - root_mean_squared_error: 1.2030\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4222 - root_mean_squared_error: 1.2030\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4505 - root_mean_squared_error: 1.2039   \n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4510 - root_mean_squared_error: 1.2042\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4504 - root_mean_squared_error: 1.2039\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4508 - root_mean_squared_error: 1.2041\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4504 - root_mean_squared_error: 1.2040\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4499 - root_mean_squared_error: 1.2038\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4485 - root_mean_squared_error: 1.2032\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4476 - root_mean_squared_error: 1.2029\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4463 - root_mean_squared_error: 1.2023\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4470 - root_mean_squared_error: 1.2023\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4456 - root_mean_squared_error: 1.2021\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4455 - root_mean_squared_error: 1.2020\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4453 - root_mean_squared_error: 1.2019\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4445 - root_mean_squared_error: 1.2016\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4438 - root_mean_squared_error: 1.2013\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4436 - root_mean_squared_error: 1.2013\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4430 - root_mean_squared_error: 1.2010\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4427 - root_mean_squared_error: 1.2009\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4430 - root_mean_squared_error: 1.2011\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4432 - root_mean_squared_error: 1.2011\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4431 - root_mean_squared_error: 1.2011\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4427 - root_mean_squared_error: 1.2009\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4422 - root_mean_squared_error: 1.2007\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4416 - root_mean_squared_error: 1.2005\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4408 - root_mean_squared_error: 1.2001\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4397 - root_mean_squared_error: 1.1997\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4387 - root_mean_squared_error: 1.1993\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4377 - root_mean_squared_error: 1.1989\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4366 - root_mean_squared_error: 1.1984\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4357 - root_mean_squared_error: 1.1980\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4347 - root_mean_squared_error: 1.1976\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4336 - root_mean_squared_error: 1.1971\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4324 - root_mean_squared_error: 1.1966\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4311 - root_mean_squared_error: 1.1961\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4298 - root_mean_squared_error: 1.1956 - val_loss: 1.3717 - val_root_mean_squared_error: 1.1712\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.2069 - root_mean_squared_error: 1.0986\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2061 - root_mean_squared_error: 1.0982\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2896 - root_mean_squared_error: 1.1478\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3362 - root_mean_squared_error: 1.1550\n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3200 - root_mean_squared_error: 1.1550\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3506 - root_mean_squared_error: 1.1613\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3553 - root_mean_squared_error: 1.1634\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3713 - root_mean_squared_error: 1.1702\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3821 - root_mean_squared_error: 1.1748\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3874 - root_mean_squared_error: 1.1772\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3872 - root_mean_squared_error: 1.1772\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3860 - root_mean_squared_error: 1.1767\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3849 - root_mean_squared_error: 1.1762\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 872ms/step - loss: 37.8714 - root_mean_squared_error: 6.1540\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.4386 - root_mean_squared_error: 6.0344\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 37.7713 - root_mean_squared_error: 6.1458\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34.9191 - root_mean_squared_error: 5.9033\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 33.3142 - root_mean_squared_error: 5.7598\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.7255 - root_mean_squared_error: 5.6126\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 30.2146 - root_mean_squared_error: 5.3297  \n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 28.8174 - root_mean_squared_error: 5.1982  \n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27.5257 - root_mean_squared_error: 5.1982  \n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.3095 - root_mean_squared_error: 4.9650\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.3697 - root_mean_squared_error: 4.9650\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.4553 - root_mean_squared_error: 4.7612\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.3405 - root_mean_squared_error: 4.8595\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.6464 - root_mean_squared_error: 4.6699\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21.2063 - root_mean_squared_error: 4.5031\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.8985 - root_mean_squared_error: 4.5840\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.5654 - root_mean_squared_error: 4.4271\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 19.9716 - root_mean_squared_error: 4.3557\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19.4170 - root_mean_squared_error: 4.2881\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18.8976 - root_mean_squared_error: 4.2240\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18.4096 - root_mean_squared_error: 4.1629\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.9508 - root_mean_squared_error: 4.1047\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.5190 - root_mean_squared_error: 4.0494\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.1119 - root_mean_squared_error: 3.9967\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 16.7275 - root_mean_squared_error: 3.9464\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 16.3641 - root_mean_squared_error: 3.8983\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 16.0193 - root_mean_squared_error: 3.8523\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 15.6933 - root_mean_squared_error: 3.8085\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 15.3830 - root_mean_squared_error: 3.7664\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 15.0883 - root_mean_squared_error: 3.7261\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 14.8069 - root_mean_squared_error: 3.6873\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 14.5382 - root_mean_squared_error: 3.6499\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 14.2811 - root_mean_squared_error: 3.6139\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 14.0353 - root_mean_squared_error: 3.5792\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13.7998 - root_mean_squared_error: 3.5457\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13.5742 - root_mean_squared_error: 3.5134\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13.3580 - root_mean_squared_error: 3.4822\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 13.1502 - root_mean_squared_error: 3.4521\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 12.9505 - root_mean_squared_error: 3.4229\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 12.7581 - root_mean_squared_error: 3.3947\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 12.5727 - root_mean_squared_error: 3.3673\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 12.3939 - root_mean_squared_error: 3.3407\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 12.2211 - root_mean_squared_error: 3.3148\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 12.0543 - root_mean_squared_error: 3.2897\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 11.8936 - root_mean_squared_error: 3.2654\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 11.7383 - root_mean_squared_error: 3.2418\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 11.5896 - root_mean_squared_error: 3.2192 - val_loss: 1.3157 - val_root_mean_squared_error: 1.1471\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2998 - root_mean_squared_error: 1.1331\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - loss: 1.4019 - root_mean_squared_error: 1.1392\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2854 - root_mean_squared_error: 1.1331\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2487 - root_mean_squared_error: 1.0972\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2070 - root_mean_squared_error: 1.0972\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1774 - root_mean_squared_error: 1.0835\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1573 - root_mean_squared_error: 1.0741\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1460 - root_mean_squared_error: 1.0690\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1399 - root_mean_squared_error: 1.0652\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1432 - root_mean_squared_error: 1.0664\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1369 - root_mean_squared_error: 1.0653\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1359 - root_mean_squared_error: 1.0653\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1370 - root_mean_squared_error: 1.0653\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1359 - root_mean_squared_error: 1.0649  \n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1344 - root_mean_squared_error: 1.0642\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1319 - root_mean_squared_error: 1.0631\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1287 - root_mean_squared_error: 1.0617\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1270 - root_mean_squared_error: 1.0609\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1252 - root_mean_squared_error: 1.0601\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1241 - root_mean_squared_error: 1.0596\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1221 - root_mean_squared_error: 1.0587\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1207 - root_mean_squared_error: 1.0580\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1190 - root_mean_squared_error: 1.0572\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1203 - root_mean_squared_error: 1.0579\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1211 - root_mean_squared_error: 1.0583\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1220 - root_mean_squared_error: 1.0587\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1228 - root_mean_squared_error: 1.0591\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1233 - root_mean_squared_error: 1.0594\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1239 - root_mean_squared_error: 1.0596\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1246 - root_mean_squared_error: 1.0600\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1251 - root_mean_squared_error: 1.0603\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1257 - root_mean_squared_error: 1.0605\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1261 - root_mean_squared_error: 1.0608\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1262 - root_mean_squared_error: 1.0608\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1260 - root_mean_squared_error: 1.0607\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1257 - root_mean_squared_error: 1.0606\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1251 - root_mean_squared_error: 1.0603\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1244 - root_mean_squared_error: 1.0600\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1235 - root_mean_squared_error: 1.0596\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1226 - root_mean_squared_error: 1.0592\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1217 - root_mean_squared_error: 1.0587\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1206 - root_mean_squared_error: 1.0582\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1197 - root_mean_squared_error: 1.0578\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1187 - root_mean_squared_error: 1.0573\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1177 - root_mean_squared_error: 1.0568\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1165 - root_mean_squared_error: 1.0563\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.1153 - root_mean_squared_error: 1.0557 - val_loss: 0.9357 - val_root_mean_squared_error: 0.9673\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - loss: 0.8151 - root_mean_squared_error: 0.9393\n",
      "\u001b[1m 6/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8701 - root_mean_squared_error: 0.9326\n",
      "\u001b[1m 5/46\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8698 - root_mean_squared_error: 0.9326\n",
      "\u001b[1m 2/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8837 - root_mean_squared_error: 0.9393\n",
      "\u001b[1m 3/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8800 - root_mean_squared_error: 0.9326\n",
      "\u001b[1m 4/46\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8853 - root_mean_squared_error: 0.9326\n",
      "\u001b[1m 7/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8672 - root_mean_squared_error: 0.9286\n",
      "\u001b[1m 8/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8628 - root_mean_squared_error: 0.9290\n",
      "\u001b[1m10/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8634 - root_mean_squared_error: 0.9291\n",
      "\u001b[1m11/46\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8633 - root_mean_squared_error: 0.9291\n",
      "\u001b[1m 9/46\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8634 - root_mean_squared_error: 0.9290\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8635 - root_mean_squared_error: 0.9291\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8635 - root_mean_squared_error: 0.9291  \n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8631 - root_mean_squared_error: 0.9289\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8614 - root_mean_squared_error: 0.9280\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8596 - root_mean_squared_error: 0.9270\n",
      "\u001b[1m17/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8579 - root_mean_squared_error: 0.9261\n",
      "\u001b[1m18/46\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8568 - root_mean_squared_error: 0.9255\n",
      "\u001b[1m19/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8558 - root_mean_squared_error: 0.9250\n",
      "\u001b[1m20/46\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8545 - root_mean_squared_error: 0.9243\n",
      "\u001b[1m21/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8534 - root_mean_squared_error: 0.9236\n",
      "\u001b[1m22/46\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8519 - root_mean_squared_error: 0.9229\n",
      "\u001b[1m23/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8506 - root_mean_squared_error: 0.9222\n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8492 - root_mean_squared_error: 0.9214\n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8475 - root_mean_squared_error: 0.9205\n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8457 - root_mean_squared_error: 0.9195\n",
      "\u001b[1m27/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8438 - root_mean_squared_error: 0.9184\n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8417 - root_mean_squared_error: 0.9173\n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8399 - root_mean_squared_error: 0.9163\n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8382 - root_mean_squared_error: 0.9153\n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8365 - root_mean_squared_error: 0.9144\n",
      "\u001b[1m32/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8349 - root_mean_squared_error: 0.9135\n",
      "\u001b[1m33/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8333 - root_mean_squared_error: 0.9126\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8319 - root_mean_squared_error: 0.9118\n",
      "\u001b[1m35/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8304 - root_mean_squared_error: 0.9110\n",
      "\u001b[1m36/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8295 - root_mean_squared_error: 0.9106\n",
      "\u001b[1m37/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8286 - root_mean_squared_error: 0.9100\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8279 - root_mean_squared_error: 0.9096\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8272 - root_mean_squared_error: 0.9093\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8263 - root_mean_squared_error: 0.9088\n",
      "\u001b[1m41/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8256 - root_mean_squared_error: 0.9084\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8248 - root_mean_squared_error: 0.9080\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8242 - root_mean_squared_error: 0.9076\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8236 - root_mean_squared_error: 0.9073\n",
      "\u001b[1m45/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8229 - root_mean_squared_error: 0.9069\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8222 - root_mean_squared_error: 0.9065\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.8215 - root_mean_squared_error: 0.9061 - val_loss: 0.7429 - val_root_mean_squared_error: 0.8619\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.6393 - root_mean_squared_error: 0.7995\n",
      "\u001b[1m 2/12\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6205 - root_mean_squared_error: 0.7877\n",
      "\u001b[1m 3/12\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6591 - root_mean_squared_error: 0.8111\n",
      "\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6743 - root_mean_squared_error: 0.8205\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6940 - root_mean_squared_error: 0.8325\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6857 - root_mean_squared_error: 0.8325\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7000 - root_mean_squared_error: 0.8483\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7209 - root_mean_squared_error: 0.8483\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7111 - root_mean_squared_error: 0.8483\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7271 - root_mean_squared_error: 0.8520\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7291 - root_mean_squared_error: 0.8532\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7302 - root_mean_squared_error: 0.8539\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7312 - root_mean_squared_error: 0.8545\n",
      "\n",
      "100%|██████████| 4/4 [01:55<00:00, 28.98s/trial, best loss: 0.8618882894515991]\n",
      "Best parameters: {'lr': 0.007850401994099254, 'momentum': 0.5902447602229833}\n",
      "Best eval rmse: 0.8618882894515991\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Run '9e0b52639ab44e6a864f5bd2f460fe42' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m serving_payload \u001b[38;5;241m=\u001b[39m convert_input_example_to_serving_input(test_x)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Validate the serving payload works on the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mvalidate_serving_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserving_payload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\models\\utils.py:2006\u001b[0m, in \u001b[0;36mvalidate_serving_input\u001b[1;34m(model_uri, serving_input)\u001b[0m\n\u001b[0;32m   2003\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m get_local_path_or_none(model_uri) \u001b[38;5;28;01melse\u001b[39;00m create_tmp_dir()\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2006\u001b[0m     pyfunc_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2007\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m _parse_json_data(\n\u001b[0;32m   2008\u001b[0m         serving_input,\n\u001b[0;32m   2009\u001b[0m         pyfunc_model\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m   2010\u001b[0m         pyfunc_model\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_input_schema(),\n\u001b[0;32m   2011\u001b[0m     )\n\u001b[0;32m   2012\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _simulate_serving_environment():\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\tracing\\provider.py:422\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m disable()\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     enable()\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:1091\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[0;32m   1089\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1091\u001b[0m local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineage_header_info\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[0;32m   1096\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:108\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[1;32m--> 108\u001b[0m repo \u001b[38;5;241m=\u001b[39m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[0;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[0;32m    115\u001b[0m     )\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:131\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[1;34m(artifact_uri)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArtifactRepository:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        requirements.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_artifact_repository_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:76\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[1;34m(self, artifact_uri)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:26\u001b[0m, in \u001b[0;36mRunsArtifactRepository.__init__\u001b[1;34m(self, artifact_uri)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact_repository_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_artifact_repository\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(artifact_uri)\n\u001b[1;32m---> 26\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[43mRunsArtifactRepository\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_underlying_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:39\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri)\u001b[0m\n\u001b[0;32m     37\u001b[0m (run_id, artifact_path) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(runs_uri)\n\u001b[0;32m     38\u001b[0m tracking_uri \u001b[38;5;241m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[1;32m---> 39\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[43mget_artifact_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(uri)  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(uri, tracking_uri)\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:52\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[1;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     47\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA run_id must be specified in order to obtain an artifact uri!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     49\u001b[0m     )\n\u001b[0;32m     51\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(tracking_uri)\n\u001b[1;32m---> 52\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlparse(run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39martifact_uri)\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:699\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mNote: Will get both active and deleted runs.\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    698\u001b[0m _validate_run_id(run_id)\n\u001b[1;32m--> 699\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_run_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m metadata is in invalid state.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_STATE,\n\u001b[0;32m    704\u001b[0m     )\n",
      "File \u001b[1;32md:\\GEN-AI\\LAB-SCENARIOS\\.conda\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:724\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[1;34m(self, run_uuid)\u001b[0m\n\u001b[0;32m    722\u001b[0m exp_id, run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_run_root(run_uuid)\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[0;32m    726\u001b[0m     )\n\u001b[0;32m    727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "\u001b[1;31mMlflowException\u001b[0m: Run '9e0b52639ab44e6a864f5bd2f460fe42' not found"
     ]
    }
   ],
   "source": [
    "## Inferencing\n",
    "\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/9e0b52639ab44e6a864f5bd2f460fe42/model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.2569876],\n",
       "       [7.2708473],\n",
       "       [5.690359 ],\n",
       "       ...,\n",
       "       [6.881361 ],\n",
       "       [6.6991577],\n",
       "       [4.748927 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model as a PyFuncModel.\n",
    "model_uri = 'runs:/9e0b52639ab44e6a864f5bd2f460fe42/model'\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'wine-quality'.\n",
      "Created version '1' of model 'wine-quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1727548664831, current_stage='None', description=None, last_updated_timestamp=1727548664831, name='wine-quality', run_id='9e0b52639ab44e6a864f5bd2f460fe42', run_link=None, source='file:///e:/UDemy%20Final/MlFlowStarter/2-DLMLFLOW/mlruns/929139454095764868/9e0b52639ab44e6a864f5bd2f460fe42/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Register in the model registry\n",
    "mlflow.register_model(model_uri,\"wine-quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
